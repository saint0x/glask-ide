// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.5.1
// - protoc             v5.29.3
// source: internal/ai/proto/ai_service.proto

package proto

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.64.0 or later.
const _ = grpc.SupportPackageIsVersion9

const (
	AIService_Complete_FullMethodName       = "/ai.AIService/Complete"
	AIService_StreamComplete_FullMethodName = "/ai.AIService/StreamComplete"
	AIService_GetModels_FullMethodName      = "/ai.AIService/GetModels"
	AIService_SetActiveModel_FullMethodName = "/ai.AIService/SetActiveModel"
)

// AIServiceClient is the client API for AIService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type AIServiceClient interface {
	// Complete handles single completion requests
	Complete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (*CompletionResponse, error)
	// StreamComplete handles streaming completion requests
	StreamComplete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (grpc.ServerStreamingClient[CompletionChunk], error)
	// GetModels returns available AI models
	GetModels(ctx context.Context, in *GetModelsRequest, opts ...grpc.CallOption) (*GetModelsResponse, error)
	// SetActiveModel changes the current model
	SetActiveModel(ctx context.Context, in *SetActiveModelRequest, opts ...grpc.CallOption) (*SetActiveModelResponse, error)
}

type aIServiceClient struct {
	cc grpc.ClientConnInterface
}

func NewAIServiceClient(cc grpc.ClientConnInterface) AIServiceClient {
	return &aIServiceClient{cc}
}

func (c *aIServiceClient) Complete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (*CompletionResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(CompletionResponse)
	err := c.cc.Invoke(ctx, AIService_Complete_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aIServiceClient) StreamComplete(ctx context.Context, in *CompletionRequest, opts ...grpc.CallOption) (grpc.ServerStreamingClient[CompletionChunk], error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	stream, err := c.cc.NewStream(ctx, &AIService_ServiceDesc.Streams[0], AIService_StreamComplete_FullMethodName, cOpts...)
	if err != nil {
		return nil, err
	}
	x := &grpc.GenericClientStream[CompletionRequest, CompletionChunk]{ClientStream: stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type AIService_StreamCompleteClient = grpc.ServerStreamingClient[CompletionChunk]

func (c *aIServiceClient) GetModels(ctx context.Context, in *GetModelsRequest, opts ...grpc.CallOption) (*GetModelsResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(GetModelsResponse)
	err := c.cc.Invoke(ctx, AIService_GetModels_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *aIServiceClient) SetActiveModel(ctx context.Context, in *SetActiveModelRequest, opts ...grpc.CallOption) (*SetActiveModelResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(SetActiveModelResponse)
	err := c.cc.Invoke(ctx, AIService_SetActiveModel_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// AIServiceServer is the server API for AIService service.
// All implementations must embed UnimplementedAIServiceServer
// for forward compatibility.
type AIServiceServer interface {
	// Complete handles single completion requests
	Complete(context.Context, *CompletionRequest) (*CompletionResponse, error)
	// StreamComplete handles streaming completion requests
	StreamComplete(*CompletionRequest, grpc.ServerStreamingServer[CompletionChunk]) error
	// GetModels returns available AI models
	GetModels(context.Context, *GetModelsRequest) (*GetModelsResponse, error)
	// SetActiveModel changes the current model
	SetActiveModel(context.Context, *SetActiveModelRequest) (*SetActiveModelResponse, error)
	mustEmbedUnimplementedAIServiceServer()
}

// UnimplementedAIServiceServer must be embedded to have
// forward compatible implementations.
//
// NOTE: this should be embedded by value instead of pointer to avoid a nil
// pointer dereference when methods are called.
type UnimplementedAIServiceServer struct{}

func (UnimplementedAIServiceServer) Complete(context.Context, *CompletionRequest) (*CompletionResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Complete not implemented")
}
func (UnimplementedAIServiceServer) StreamComplete(*CompletionRequest, grpc.ServerStreamingServer[CompletionChunk]) error {
	return status.Errorf(codes.Unimplemented, "method StreamComplete not implemented")
}
func (UnimplementedAIServiceServer) GetModels(context.Context, *GetModelsRequest) (*GetModelsResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetModels not implemented")
}
func (UnimplementedAIServiceServer) SetActiveModel(context.Context, *SetActiveModelRequest) (*SetActiveModelResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method SetActiveModel not implemented")
}
func (UnimplementedAIServiceServer) mustEmbedUnimplementedAIServiceServer() {}
func (UnimplementedAIServiceServer) testEmbeddedByValue()                   {}

// UnsafeAIServiceServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to AIServiceServer will
// result in compilation errors.
type UnsafeAIServiceServer interface {
	mustEmbedUnimplementedAIServiceServer()
}

func RegisterAIServiceServer(s grpc.ServiceRegistrar, srv AIServiceServer) {
	// If the following call pancis, it indicates UnimplementedAIServiceServer was
	// embedded by pointer and is nil.  This will cause panics if an
	// unimplemented method is ever invoked, so we test this at initialization
	// time to prevent it from happening at runtime later due to I/O.
	if t, ok := srv.(interface{ testEmbeddedByValue() }); ok {
		t.testEmbeddedByValue()
	}
	s.RegisterService(&AIService_ServiceDesc, srv)
}

func _AIService_Complete_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CompletionRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AIServiceServer).Complete(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AIService_Complete_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AIServiceServer).Complete(ctx, req.(*CompletionRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AIService_StreamComplete_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(CompletionRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(AIServiceServer).StreamComplete(m, &grpc.GenericServerStream[CompletionRequest, CompletionChunk]{ServerStream: stream})
}

// This type alias is provided for backwards compatibility with existing code that references the prior non-generic stream type by name.
type AIService_StreamCompleteServer = grpc.ServerStreamingServer[CompletionChunk]

func _AIService_GetModels_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetModelsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AIServiceServer).GetModels(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AIService_GetModels_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AIServiceServer).GetModels(ctx, req.(*GetModelsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _AIService_SetActiveModel_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(SetActiveModelRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(AIServiceServer).SetActiveModel(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: AIService_SetActiveModel_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(AIServiceServer).SetActiveModel(ctx, req.(*SetActiveModelRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// AIService_ServiceDesc is the grpc.ServiceDesc for AIService service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var AIService_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "ai.AIService",
	HandlerType: (*AIServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "Complete",
			Handler:    _AIService_Complete_Handler,
		},
		{
			MethodName: "GetModels",
			Handler:    _AIService_GetModels_Handler,
		},
		{
			MethodName: "SetActiveModel",
			Handler:    _AIService_SetActiveModel_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamComplete",
			Handler:       _AIService_StreamComplete_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "internal/ai/proto/ai_service.proto",
}
